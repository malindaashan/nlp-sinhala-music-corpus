{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "af398bc8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import unicodedata\n",
    "import re\n",
    "import nltk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a30f85cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_df = pd.read_csv(r\"C:\\Users\\MalindaPieris\\Documents\\MscResearch\\Sinhala-Audio-Classfication-notebooks\\notebooks\\nlp\\dataset-metadata -with-lyrics.csv\")\n",
    "data_df = pd.DataFrame(data_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b1a792a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def lineBreakReplace(text):\n",
    "    return text.replace(\"\\r\\n\", \" \")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "19aaf9de",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_df['Lyrics'] =data_df.apply(lambda x: lineBreakReplace(x.Lyrics), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "85c468d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def removeEscapSequences(text):\n",
    "    return \"\".join(ch for ch in text if unicodedata.category(ch)[0]!=\"C\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "4e767818",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_df['Lyrics'] =data_df.apply(lambda x: removeEscapSequences(x.Lyrics), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ec360e61",
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_digits(text):\n",
    "    return ''.join([i for i in text if not i.isdigit()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "0ff52324",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_df['Lyrics'] =data_df.apply(lambda x: removeEscapSequences(x.Lyrics), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "7c8b90f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def removeHtmlTags(text):\n",
    "    p = re.compile(r'<.*?>')\n",
    "    return p.sub('', text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "a19ab1f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_df['Lyrics'] = data_df.apply(lambda x: removeHtmlTags(x.Lyrics), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "6f7710d2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>song_id</th>\n",
       "      <th>song_name</th>\n",
       "      <th>Artist</th>\n",
       "      <th>Lyrics</th>\n",
       "      <th>Type</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>C 01</td>\n",
       "      <td>Kaulu Piyan Path Wahanna</td>\n",
       "      <td>Kasun Kalhara</td>\n",
       "      <td>කවුළු පියන්පත් වහන්න සඳළුතලාවේ ඔබ දුරයි නෙතට ම...</td>\n",
       "      <td>Calm</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>C 02</td>\n",
       "      <td>Ruk Aththana Mala Mudune\\n</td>\n",
       "      <td>Nanda Malini</td>\n",
       "      <td>රුක් අත්තන මල මුදුනේ  බඹරු නටන හැන්දෑවේ… සැදෑ ...</td>\n",
       "      <td>Calm</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>C 03</td>\n",
       "      <td>Samanala Mudune</td>\n",
       "      <td>H R Jothipala and Latha Walpola</td>\n",
       "      <td>සමනළ මුදුනේ සිරිපද සිඹ සිඹ උදා ඉරක් පායයි සැන...</td>\n",
       "      <td>Calm</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>C 04</td>\n",
       "      <td>Niwan Dutu Himi</td>\n",
       "      <td>Victor Rathnayaka</td>\n",
       "      <td>නිවන් දුටු හිමි රැවන් පිළිරැව පමණි මට අද ශේෂ ව...</td>\n",
       "      <td>Calm</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>C 05</td>\n",
       "      <td>Suwanda Danee Danee Danenawa</td>\n",
       "      <td>Rookantha Gunathilake</td>\n",
       "      <td>සුවඳ දැනී දැනී දැනෙනවා... උදා හිරු එළියේ... අළ...</td>\n",
       "      <td>Calm</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  song_id                     song_name                           Artist  \\\n",
       "0    C 01      Kaulu Piyan Path Wahanna                    Kasun Kalhara   \n",
       "1    C 02    Ruk Aththana Mala Mudune\\n                     Nanda Malini   \n",
       "2    C 03               Samanala Mudune  H R Jothipala and Latha Walpola   \n",
       "3    C 04               Niwan Dutu Himi                Victor Rathnayaka   \n",
       "4    C 05  Suwanda Danee Danee Danenawa            Rookantha Gunathilake   \n",
       "\n",
       "                                              Lyrics  Type  \n",
       "0  කවුළු පියන්පත් වහන්න සඳළුතලාවේ ඔබ දුරයි නෙතට ම...  Calm  \n",
       "1  රුක් අත්තන මල මුදුනේ  බඹරු නටන හැන්දෑවේ… සැදෑ ...  Calm  \n",
       "2   සමනළ මුදුනේ සිරිපද සිඹ සිඹ උදා ඉරක් පායයි සැන...  Calm  \n",
       "3  නිවන් දුටු හිමි රැවන් පිළිරැව පමණි මට අද ශේෂ ව...  Calm  \n",
       "4  සුවඳ දැනී දැනී දැනෙනවා... උදා හිරු එළියේ... අළ...  Calm  "
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "486354e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def removeSpecialCharacters(sentence,keep_apostrophes=True):\n",
    "    sentence = sentence.strip()\n",
    "    if keep_apostrophes:\n",
    "        PATTERN = r'[?|$|&|*|%|@|(|)|~]'\n",
    "        filtered_sentence = re.sub(PATTERN, r'', sentence)\n",
    "        return filtered_sentence\n",
    "    return sentence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "56ae41d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def replace_full_stops(sentence):\n",
    "    return sentence.replace(\".\",\" \")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "945365a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_df['Lyrics'] = data_df.apply(lambda x: removeSpecialCharacters(x.Lyrics), axis=1)\n",
    "data_df['Lyrics'] = data_df.apply(lambda x: replace_full_stops(x.Lyrics), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "40490828",
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_english_letters(sentence):\n",
    "    non_english_sentence = re.sub(r'[a-zA-Z]', '', sentence)\n",
    "    return non_english_sentence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "59e5fe52",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_df['Lyrics']  = data_df['Lyrics'] .apply(lambda x: remove_english_letters(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "40b69c33",
   "metadata": {},
   "outputs": [],
   "source": [
    "lines = list(open('stop-words-sinhala.txt',encoding=\"utf8\"))\n",
    "sinhala_stop_words = [re.sub(\"\\n\",\"\",x) for x in lines]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "2651903c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def tokenize_text(text):\n",
    "    tokens = nltk.word_tokenize(text)\n",
    "    tokens = [token.strip() for token in tokens]\n",
    "    return tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "1cf1abf9",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_df['token_list']  = data_df['Lyrics'] .apply(lambda x: tokenize_text(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "5b38a21b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_sinhala_stop_words(tokens):\n",
    "    filtered_tokens = [token for token in tokens if token not in sinhala_stop_words]\n",
    "    return filtered_tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "7a6d0f65",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_df['token_list_after_sw'] = data_df.apply(lambda x: remove_sinhala_stop_words(x.token_list), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "b3aee7d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_two_letter_words(tokenized_words):\n",
    "    # Use list comprehension to filter out words with length 2\n",
    "    filtered_words = [word for word in tokenized_words if len(word) > 3]\n",
    "    return filtered_words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "fcb0a8df",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_df['token_list_after_sw'] = data_df.apply(lambda x: remove_two_letter_words(x.token_list_after_sw), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "8a43079e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.tokenize.treebank import TreebankWordDetokenizer\n",
    "data_df['pre_processed_text'] = data_df.apply(lambda x: TreebankWordDetokenizer().detokenize(x.token_list_after_sw), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "9cbe3d6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import Counter\n",
    "import numpy as np\n",
    "list_of_words = ' '.join(data_df['pre_processed_text']).split()\n",
    "most_common_words = [word for word, count in Counter(list_of_words).items() if count in np.arange(25,100)]\n",
    "unique_words = [word for word, count in Counter(list_of_words).items() if count in [1,2,3,4,5,6,7,8,9]]\n",
    "all_words_to_remove = most_common_words+unique_words;\n",
    "def remove_most_common_unique_words(tokens):\n",
    "    filtered_tokens = [token for token in tokens if token not in all_words_to_remove]\n",
    "    return filtered_tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "b7b0f7d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_df['token_list_after_common_words'] = data_df.apply(lambda x: remove_most_common_unique_words(x.token_list_after_sw), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "a9cdc18a",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_df['pre_processed_text'] = data_df.apply(lambda x: TreebankWordDetokenizer().detokenize(x.token_list_after_common_words), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "83d50486",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Counter({'නෙතට': 10,\n",
       "         'තලාවේ': 10,\n",
       "         'මුදුනේ': 10,\n",
       "         'බඹරු': 10,\n",
       "         'අඳුර': 11,\n",
       "         'කවුරුද': 14,\n",
       "         'එන්නේ…': 10,\n",
       "         'නුවන්': 23,\n",
       "         'මුතු': 24,\n",
       "         'පිණි': 11,\n",
       "         'හිරු': 14,\n",
       "         'පුරා': 15,\n",
       "         'දැහැමි': 10,\n",
       "         'දැයක්': 10,\n",
       "         'පිබිදෙයි': 10,\n",
       "         'නිවන්': 10,\n",
       "         'දුටු': 15,\n",
       "         'මැනවී': 17,\n",
       "         'බුදු': 14,\n",
       "         'කරැණාවෙන්': 21,\n",
       "         'අතින්': 12,\n",
       "         'මලක්': 14,\n",
       "         'දැනී': 10,\n",
       "         'එළියේ': 24,\n",
       "         'හැඟුම්': 18,\n",
       "         'ලස්සන': 20,\n",
       "         'ඇවිදින්': 21,\n",
       "         'දිගේ': 19,\n",
       "         'ජීවිතේ': 13,\n",
       "         'සුන්දර': 11,\n",
       "         'නොවී': 12,\n",
       "         'කල්පනා': 13,\n",
       "         'සැලෙන': 15,\n",
       "         'රහසේ': 13,\n",
       "         'පහන්': 20,\n",
       "         'හදින්': 12,\n",
       "         'ලොවක්': 10,\n",
       "         'අහසේ': 12,\n",
       "         'යහනේ': 10,\n",
       "         'පැන්': 11,\n",
       "         'පොදක්': 16,\n",
       "         'ආදරෙයි': 18,\n",
       "         'සිරි': 17,\n",
       "         'ඔබගේ': 20,\n",
       "         'මතකයි': 20,\n",
       "         'කියලා': 11,\n",
       "         'මිහිරි': 16,\n",
       "         'නැගෙන': 12,\n",
       "         'බැදුනු': 10,\n",
       "         'ප්රේමයේ': 14,\n",
       "         'නමින්': 10,\n",
       "         'හැටි': 15,\n",
       "         'කුසුම්': 12,\n",
       "         'හමයි': 12,\n",
       "         'අතරේ': 14,\n",
       "         'වසන්තේ': 21,\n",
       "         'කඳුළු': 16,\n",
       "         'හඬනා': 11,\n",
       "         'රැයේ': 20,\n",
       "         'සුසුම්': 11,\n",
       "         'ආදරයේ': 19,\n",
       "         'පාසැල්': 13,\n",
       "         'ගමන්': 10,\n",
       "         'කියන්න': 11,\n",
       "         'ආසයි': 13,\n",
       "         'කොයි': 11,\n",
       "         'නිල්': 21,\n",
       "         'සිත්': 10,\n",
       "         'ප්රේම': 17,\n",
       "         'බිංදු': 12,\n",
       "         'රැන්දු': 12,\n",
       "         'ගොයමේ': 15,\n",
       "         'සින්දු': 22,\n",
       "         'ලන්දු': 12,\n",
       "         'සොඳුරු': 21,\n",
       "         'රුවන්': 14,\n",
       "         'ඉන්නේ': 14,\n",
       "         'සිරියා': 11,\n",
       "         'ළමුන්': 11,\n",
       "         'නිදි': 10,\n",
       "         'අභිමන්': 10,\n",
       "         'පිරිලා': 11,\n",
       "         'එනවා': 18,\n",
       "         'ලොවෙන්': 10,\n",
       "         'නැති': 23,\n",
       "         'ටිකිරි': 18,\n",
       "         'ලංවී': 10,\n",
       "         'නංගී': 16,\n",
       "         'මල්ලී': 11,\n",
       "         'කාලය': 10,\n",
       "         'සෙනෙහස': 10,\n",
       "         'පිපි': 13,\n",
       "         'ප්රිය': 15,\n",
       "         'ආදරණීය': 14,\n",
       "         'නේරංජනා': 14,\n",
       "         'කිරි': 20,\n",
       "         'කැන්': 17,\n",
       "         'පානේ': 16,\n",
       "         'වෙන්න': 16,\n",
       "         'තමයි': 12,\n",
       "         'සෙනෙහසින්': 12,\n",
       "         'නිවා': 10,\n",
       "         'කැලේ': 11,\n",
       "         'හැමදාම': 11,\n",
       "         'මාගේ': 18,\n",
       "         'මමයි': 17,\n",
       "         'යාමේ': 13,\n",
       "         'මිණි': 13,\n",
       "         'වෙලේ': 11,\n",
       "         'හොහෝ': 11,\n",
       "         'වරෙන්': 18,\n",
       "         'අපිත්': 12,\n",
       "         'දෑසෙ': 10,\n",
       "         'පටලා': 11,\n",
       "         'සොඳුරී': 10,\n",
       "         'උදාවුනා': 12,\n",
       "         'එළිය': 16,\n",
       "         'දෙපස': 10,\n",
       "         'ඉතිරේ': 10,\n",
       "         'දීපන්ගීමන': 11,\n",
       "         'කාලේ': 16,\n",
       "         'යුවලක්': 10,\n",
       "         'කෙරේ': 13,\n",
       "         'පොහොය': 10,\n",
       "         'තේජමාන': 10,\n",
       "         'උපන්': 10,\n",
       "         'පුතේ': 17,\n",
       "         'දුවේ': 12,\n",
       "         'ඉපදුන': 10,\n",
       "         'සිරිලක්': 10,\n",
       "         'බිමේ': 12,\n",
       "         'දළදා': 15,\n",
       "         'පිරුණු': 10,\n",
       "         'වෙමි': 10,\n",
       "         'රන්වන්': 19,\n",
       "         'ගුම්': 21,\n",
       "         'දිලිසෙන': 13,\n",
       "         'මැණිකේ': 24,\n",
       "         'සැගවී': 10,\n",
       "         'කෙත්වතු': 10,\n",
       "         'සාරා': 10,\n",
       "         'පිපුණු': 10,\n",
       "         'අම්මා': 24,\n",
       "         'යැදුමට': 11,\n",
       "         'පිදුමට': 11,\n",
       "         'කවිය': 15,\n",
       "         'අම්මේ': 18,\n",
       "         'තනියට': 12,\n",
       "         'ඇදුම': 12,\n",
       "         'වියන්නේ': 17,\n",
       "         'ලඳුනේ': 12,\n",
       "         'කුරුටු': 10})"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list_of_words = ' '.join(data_df['pre_processed_text']).split()\n",
    "Counter(list_of_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "a02a54cf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>song_id</th>\n",
       "      <th>song_name</th>\n",
       "      <th>Artist</th>\n",
       "      <th>Lyrics</th>\n",
       "      <th>Type</th>\n",
       "      <th>token_list</th>\n",
       "      <th>token_list_after_sw</th>\n",
       "      <th>pre_processed_text</th>\n",
       "      <th>token_list_after_common_words</th>\n",
       "      <th>word_count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>C 01</td>\n",
       "      <td>Kaulu Piyan Path Wahanna</td>\n",
       "      <td>Kasun Kalhara</td>\n",
       "      <td>කවුළු පියන්පත් වහන්න සඳළුතලාවේ ඔබ දුරයි නෙතට ම...</td>\n",
       "      <td>Calm</td>\n",
       "      <td>[කවුළු, පියන්පත්, වහන්න, සඳළුතලාවේ, ඔබ, දුරයි,...</td>\n",
       "      <td>[කවුළු, පියන්පත්, වහන්න, සඳළුතලාවේ, දුරයි, නෙත...</td>\n",
       "      <td>නෙතට තලාවේ නෙතට තලාවේ නෙතට තලාවේ නෙතට තලාවේ නෙ...</td>\n",
       "      <td>[නෙතට, තලාවේ, නෙතට, තලාවේ, නෙතට, තලාවේ, නෙතට, ...</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>C 02</td>\n",
       "      <td>Ruk Aththana Mala Mudune\\n</td>\n",
       "      <td>Nanda Malini</td>\n",
       "      <td>රුක් අත්තන මල මුදුනේ  බඹරු නටන හැන්දෑවේ… සැදෑ ...</td>\n",
       "      <td>Calm</td>\n",
       "      <td>[රුක්, අත්තන, මල, මුදුනේ, බඹරු, නටන, හැන්දෑවේ…...</td>\n",
       "      <td>[රුක්, අත්තන, මුදුනේ, බඹරු, හැන්දෑවේ…, සැදෑ, අ...</td>\n",
       "      <td>මුදුනේ බඹරු අඳුර කවුරුද එන්නේ… නුවන් කවුරුද එන...</td>\n",
       "      <td>[මුදුනේ, බඹරු, අඳුර, කවුරුද, එන්නේ…, නුවන්, කව...</td>\n",
       "      <td>38</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>C 03</td>\n",
       "      <td>Samanala Mudune</td>\n",
       "      <td>H R Jothipala and Latha Walpola</td>\n",
       "      <td>සමනළ මුදුනේ සිරිපද සිඹ සිඹ උදා ඉරක් පායයි සැනස...</td>\n",
       "      <td>Calm</td>\n",
       "      <td>[සමනළ, මුදුනේ, සිරිපද, සිඹ, සිඹ, උදා, ඉරක්, පා...</td>\n",
       "      <td>[සමනළ, මුදුනේ, සිරිපද, ඉරක්, පායයි, සැනසිලි, ම...</td>\n",
       "      <td>මුදුනේ දැහැමි දැයක් පිබිදෙයි දැහැමි දැයක් පිබි...</td>\n",
       "      <td>[මුදුනේ, දැහැමි, දැයක්, පිබිදෙයි, දැහැමි, දැයක...</td>\n",
       "      <td>35</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>C 04</td>\n",
       "      <td>Niwan Dutu Himi</td>\n",
       "      <td>Victor Rathnayaka</td>\n",
       "      <td>නිවන් දුටු හිමි රැවන් පිළිරැව පමණි මට අද ශේෂ ව...</td>\n",
       "      <td>Calm</td>\n",
       "      <td>[නිවන්, දුටු, හිමි, රැවන්, පිළිරැව, පමණි, මට, ...</td>\n",
       "      <td>[නිවන්, දුටු, හිමි, රැවන්, පිළිරැව, පමණි, වුයේ...</td>\n",
       "      <td>නිවන් දුටු මැනවී බුදු කරැණාවෙන් කරැණාවෙන් කරැණ...</td>\n",
       "      <td>[නිවන්, දුටු, මැනවී, බුදු, කරැණාවෙන්, කරැණාවෙන...</td>\n",
       "      <td>33</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>C 05</td>\n",
       "      <td>Suwanda Danee Danee Danenawa</td>\n",
       "      <td>Rookantha Gunathilake</td>\n",
       "      <td>සුවඳ දැනී දැනී දැනෙනවා    උදා හිරු එළියේ    අළ...</td>\n",
       "      <td>Calm</td>\n",
       "      <td>[සුවඳ, දැනී, දැනී, දැනෙනවා, උදා, හිරු, එළියේ, ...</td>\n",
       "      <td>[සුවඳ, දැනී, දැනී, දැනෙනවා, හිරු, එළියේ, අළුත්...</td>\n",
       "      <td>දැනී දැනී හිරු එළියේ හැඟුම් දැනී දැනී ලස්සන ඇව...</td>\n",
       "      <td>[දැනී, දැනී, හිරු, එළියේ, හැඟුම්, දැනී, දැනී, ...</td>\n",
       "      <td>23</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  song_id                     song_name                           Artist  \\\n",
       "0    C 01      Kaulu Piyan Path Wahanna                    Kasun Kalhara   \n",
       "1    C 02    Ruk Aththana Mala Mudune\\n                     Nanda Malini   \n",
       "2    C 03               Samanala Mudune  H R Jothipala and Latha Walpola   \n",
       "3    C 04               Niwan Dutu Himi                Victor Rathnayaka   \n",
       "4    C 05  Suwanda Danee Danee Danenawa            Rookantha Gunathilake   \n",
       "\n",
       "                                              Lyrics  Type  \\\n",
       "0  කවුළු පියන්පත් වහන්න සඳළුතලාවේ ඔබ දුරයි නෙතට ම...  Calm   \n",
       "1  රුක් අත්තන මල මුදුනේ  බඹරු නටන හැන්දෑවේ… සැදෑ ...  Calm   \n",
       "2  සමනළ මුදුනේ සිරිපද සිඹ සිඹ උදා ඉරක් පායයි සැනස...  Calm   \n",
       "3  නිවන් දුටු හිමි රැවන් පිළිරැව පමණි මට අද ශේෂ ව...  Calm   \n",
       "4  සුවඳ දැනී දැනී දැනෙනවා    උදා හිරු එළියේ    අළ...  Calm   \n",
       "\n",
       "                                          token_list  \\\n",
       "0  [කවුළු, පියන්පත්, වහන්න, සඳළුතලාවේ, ඔබ, දුරයි,...   \n",
       "1  [රුක්, අත්තන, මල, මුදුනේ, බඹරු, නටන, හැන්දෑවේ…...   \n",
       "2  [සමනළ, මුදුනේ, සිරිපද, සිඹ, සිඹ, උදා, ඉරක්, පා...   \n",
       "3  [නිවන්, දුටු, හිමි, රැවන්, පිළිරැව, පමණි, මට, ...   \n",
       "4  [සුවඳ, දැනී, දැනී, දැනෙනවා, උදා, හිරු, එළියේ, ...   \n",
       "\n",
       "                                 token_list_after_sw  \\\n",
       "0  [කවුළු, පියන්පත්, වහන්න, සඳළුතලාවේ, දුරයි, නෙත...   \n",
       "1  [රුක්, අත්තන, මුදුනේ, බඹරු, හැන්දෑවේ…, සැදෑ, අ...   \n",
       "2  [සමනළ, මුදුනේ, සිරිපද, ඉරක්, පායයි, සැනසිලි, ම...   \n",
       "3  [නිවන්, දුටු, හිමි, රැවන්, පිළිරැව, පමණි, වුයේ...   \n",
       "4  [සුවඳ, දැනී, දැනී, දැනෙනවා, හිරු, එළියේ, අළුත්...   \n",
       "\n",
       "                                  pre_processed_text  \\\n",
       "0  නෙතට තලාවේ නෙතට තලාවේ නෙතට තලාවේ නෙතට තලාවේ නෙ...   \n",
       "1  මුදුනේ බඹරු අඳුර කවුරුද එන්නේ… නුවන් කවුරුද එන...   \n",
       "2  මුදුනේ දැහැමි දැයක් පිබිදෙයි දැහැමි දැයක් පිබි...   \n",
       "3  නිවන් දුටු මැනවී බුදු කරැණාවෙන් කරැණාවෙන් කරැණ...   \n",
       "4  දැනී දැනී හිරු එළියේ හැඟුම් දැනී දැනී ලස්සන ඇව...   \n",
       "\n",
       "                       token_list_after_common_words  word_count  \n",
       "0  [නෙතට, තලාවේ, නෙතට, තලාවේ, නෙතට, තලාවේ, නෙතට, ...          10  \n",
       "1  [මුදුනේ, බඹරු, අඳුර, කවුරුද, එන්නේ…, නුවන්, කව...          38  \n",
       "2  [මුදුනේ, දැහැමි, දැයක්, පිබිදෙයි, දැහැමි, දැයක...          35  \n",
       "3  [නිවන්, දුටු, මැනවී, බුදු, කරැණාවෙන්, කරැණාවෙන...          33  \n",
       "4  [දැනී, දැනී, හිරු, එළියේ, හැඟුම්, දැනී, දැනී, ...          23  "
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_df['word_count'] = data_df['pre_processed_text'].str.split().str.len()\n",
    "data_df.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "586c442f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total number of unique words <FreqDist with 152 samples and 2089 outcomes>\n"
     ]
    }
   ],
   "source": [
    "def total_unique_words(words):\n",
    "    return nltk.FreqDist(words)\n",
    "\n",
    "print(\"Total number of unique words\",total_unique_words(list_of_words))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "9e6f6592",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total number of words 2089\n"
     ]
    }
   ],
   "source": [
    "def total_words(words):\n",
    "    return(len(words))\n",
    "print(\"Total number of words\",total_words(list_of_words))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "e553b7e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn import preprocessing\n",
    "label_encoder = preprocessing.LabelEncoder()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "10b0f012",
   "metadata": {},
   "outputs": [],
   "source": [
    "X= data_df['pre_processed_text']\n",
    "y=label_encoder.fit_transform(data_df['Type'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "fee0b3ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X,y, test_size=0.33, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "2e64c113",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer,CountVectorizer\n",
    "\n",
    "countvectorizer = CountVectorizer(analyzer= 'word')\n",
    "tfidfvectorizer = TfidfVectorizer(analyzer='word')\n",
    "count_wm = countvectorizer.fit_transform(X_train)\n",
    "tfidf_wm = tfidfvectorizer.fit_transform(X_train)\n",
    "count_tokens = countvectorizer.get_feature_names()\n",
    "tfidf_tokens = tfidfvectorizer.get_feature_names()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "0a3f4f3f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Count Vectorizer\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>අත</th>\n",
       "      <th>අතර</th>\n",
       "      <th>අඳ</th>\n",
       "      <th>අප</th>\n",
       "      <th>අභ</th>\n",
       "      <th>අම</th>\n",
       "      <th>අහස</th>\n",
       "      <th>ආදර</th>\n",
       "      <th>ආදරණ</th>\n",
       "      <th>ආදරය</th>\n",
       "      <th>...</th>\n",
       "      <th>වන</th>\n",
       "      <th>වර</th>\n",
       "      <th>වලක</th>\n",
       "      <th>වසන</th>\n",
       "      <th>සන</th>\n",
       "      <th>හඬන</th>\n",
       "      <th>හද</th>\n",
       "      <th>හමය</th>\n",
       "      <th>හස</th>\n",
       "      <th>ළම</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.089896</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.062296</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.040715</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 69 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    අත  අතර   අඳ   අප   අභ   අම       අහස  ආදර  ආදරණ  ආදරය  ...        වන  \\\n",
       "0  0.0  0.0  0.0  0.0  0.0  0.0  0.000000  0.0   0.0   0.0  ...  0.000000   \n",
       "1  0.0  0.0  0.0  0.0  0.0  0.0  0.000000  0.0   0.0   0.0  ...  0.000000   \n",
       "2  0.0  0.0  1.0  0.0  0.0  0.0  0.000000  0.0   0.0   0.0  ...  0.000000   \n",
       "3  0.0  0.0  0.0  0.0  0.0  0.0  0.089896  0.0   0.0   0.0  ...  0.062296   \n",
       "4  0.0  0.0  0.0  0.0  0.0  0.0  0.000000  0.0   0.0   0.0  ...  0.000000   \n",
       "\n",
       "    වර  වලක  වසන        සන  හඬන   හද  හමය   හස   ළම  \n",
       "0  0.0  0.0  0.0  0.000000  0.0  0.0  0.0  0.0  0.0  \n",
       "1  0.0  0.0  0.0  0.000000  0.0  0.0  0.0  0.0  0.0  \n",
       "2  0.0  0.0  0.0  0.000000  0.0  0.0  0.0  0.0  0.0  \n",
       "3  0.0  0.0  0.0  0.040715  0.0  0.0  0.0  0.0  0.0  \n",
       "4  0.0  0.0  0.0  0.000000  0.0  0.0  0.0  0.0  0.0  \n",
       "\n",
       "[5 rows x 69 columns]"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_countvect = pd.DataFrame(data = count_wm.toarray(),columns = count_tokens)\n",
    "df_tfidfvect = pd.DataFrame(data = tfidf_wm.toarray(),columns = tfidf_tokens)\n",
    "print(\"Count Vectorizer\\n\")\n",
    "df_tfidfvect.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "989ad51b",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# tfidfvectorizer_csv = TfidfVectorizer(analyzer='word')\n",
    "# tfidf_wm_tocsv = tfidfvectorizer_csv.fit_transform(X)\n",
    "# tfidf_tokens_csv = tfidfvectorizer_csv.get_feature_names()\n",
    "# df_tfidfvect = pd.DataFrame(data = tfidf_wm_tocsv.toarray(),columns = tfidf_tokens_csv)\n",
    "\n",
    "# df_tfidfvect.to_csv(\"tfidf_all.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "69a3e981",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier()"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "random_forest = RandomForestClassifier(n_estimators=100)\n",
    "random_forest.fit(df_tfidfvect, y_train)\n",
    "#pred_forest = random_forest.predict(xtest)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "8377a424",
   "metadata": {},
   "outputs": [],
   "source": [
    "####testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "8bc541f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_countvect_test = countvectorizer.transform(X_test)\n",
    "df_tfidfvect_test = tfidfvectorizer.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "d2c631e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_forest = random_forest.predict(df_tfidfvect_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "4230e4b3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 0, 2, 0, 2, 2, 0, 2, 2, 2, 0, 0, 0, 1, 2, 2, 2, 0, 1, 2, 1, 2,\n",
       "       2, 1, 0, 1, 2, 2, 2, 2, 1, 2, 2, 2, 2, 2, 2, 2, 0, 0, 1, 2, 2, 1,\n",
       "       2, 2, 2, 2, 1, 2, 1, 2, 2, 0])"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred_forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "f94c9b27",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([2, 1, 2, 1, 1, 0, 1, 0, 1, 2, 0, 1, 0, 1, 0, 0, 2, 1, 1, 0, 1, 0,\n",
       "       0, 0, 0, 2, 1, 1, 2, 1, 2, 1, 1, 2, 0, 2, 0, 0, 1, 1, 0, 2, 1, 1,\n",
       "       2, 0, 1, 0, 2, 1, 2, 0, 1, 1])"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "f3b8afcf",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "d7259182",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 27.77777777777778\n"
     ]
    }
   ],
   "source": [
    "print(\"Accuracy:\",metrics.accuracy_score(y_test, pred_forest)*100)\n",
    "#print(\"Precision:\",metrics.precision_score(y_test, pred_forest))\n",
    "#print(\"Recall:\",metrics.recall_score(y_test, pred_forest))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "39fff293",
   "metadata": {},
   "outputs": [],
   "source": [
    "##decsion tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "6d271d8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.metrics import accuracy_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "8fe9e982",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MultinomialNB()"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "classifier = MultinomialNB()\n",
    "classifier.fit(df_tfidfvect, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "17cd41ef",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 31.48148148148148\n"
     ]
    }
   ],
   "source": [
    "y_pred = classifier.predict(df_tfidfvect_test)\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(\"Accuracy:\", accuracy*100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "047c36b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "##################EndofScript###################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "877d3a00",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6e0bb13",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
